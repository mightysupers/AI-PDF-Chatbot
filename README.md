# ğŸ§  AI PDF Chatbot using LLaMA 2 (Fully Offline)

This project allows you to chat with your own PDF documents using the LLaMA 2 model completely offline â€” no API keys required!  
Built with LangChain, FAISS, HuggingFace Embeddings, and llama-cpp-python.

## ğŸš€ Features
- Load any PDF file and convert it into chunks.
- Generate embeddings using `sentence-transformers`.
- Store & retrieve using FAISS.
- Query offline using a locally downloaded LLaMA 2 model.
- Works 100% without internet once setup.

## ğŸ“ Folder Structure

```
AI-PDF-Chatbot/
â”‚
â”œâ”€â”€ docs/                   # Your PDFs and generated chunks
â”‚   â”œâ”€â”€ sample.pdf
â”‚   â””â”€â”€ chunks.pkl
â”‚
â”œâ”€â”€ models/                 # (DO NOT upload to GitHub) contains .gguf LLaMA 2 model
â”‚
â”œâ”€â”€ load_docs.py            # Splits and chunks your PDF
â”œâ”€â”€ embed_documents.py      # Generates vector embeddings
â”œâ”€â”€ chat_with_llama.py      # Main chatbot script
â”‚
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # You're reading it!
```

## ğŸ› ï¸ Setup Instructions

```bash
# 1. Create virtual environment (optional)
python -m venv .venv
source .venv/Scripts/activate  # for Windows

# 2. Install dependencies
pip install -r requirements.txt
```

## ğŸ§  Model
Download LLaMA 2 (GGUF format) from trusted sources like HuggingFace or TheBloke. Place inside `/models/`.

## ğŸ¤– Start Chatting

```bash
python chat_with_llama.py
```

## ğŸ™ Acknowledgments
- Meta AI for LLaMA 2
- LangChain community
- HuggingFace transformers